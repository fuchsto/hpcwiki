---
title: Pipelining, Instruction-level-parallelism
format: Markdown
categories: lab
...

# Terminology

Consider this simple C snippet:

~~~c
int a = 12;
int b = 23;
// ...
a += b;
~~~

The expression `a += b` is an **operation** applied to `a` with\
argument `b` as its only argument.

Note that the term **parameter** refers to a variable in a function's
signature while an **argument** is a concrete value.
For Example:

~~~c
int confabulate(double d, int i);
// ...
confabulate(2.124, 41.99);
~~~

The variable `double d` is a parameter of function `confabulate`
which is then called with arguments `2.124` and `41.99`.

Now some low-level basics we rarely think about in our carefree everyday
lives:

- Any *operation* like `a += b` is realized in a hardware process called
  *instruction cycle*.
- A single CPU contains several functional components, each implementing
  a specific processing task (for example: ALU for bitwise boolean logic,
  FPU for floating-point calculations, MMU to translate logical addresses
  to phyiscal banks in memory, ...)
- To keep things simple and civilized, we assume Load-Store CPUs which
  can only access data in its *registers* and have no access to memory

Let's first decompose `a += b` in our examples into its procedural steps.


1. **load** value of `b` into a register $R0
2. **load** value of `a` into a register $R1
3. **calculate** `add $R0 $R1`
4. **store** result at the memory address of variable `a`

So in pseudo load-store-assembly:

~~~
load  $R1 &(`b`) // R1 <- b
load  $R0 &(`a`) // R0 <- a
add   $R3 $R0 R1 // R3 = R0 + R1
store $R3 &(`a`) // R3 -> a
~~~

> Longing for a more detailed discussion of L/S assembly? I can relate! \
> This is how it works in real life: [https://www.youtube.com/watch?v=07ATOG5wXPE]()

